{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e00218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/naeemulhassan/naeem-p/Cloud-Deployed-Multitask-IoT-IDS\n",
      "Using processed data from: /Users/naeemulhassan/naeem-p/Cloud-Deployed-Multitask-IoT-IDS/data/processed\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# --------------------------------------------------------------\n",
    "# 05_baseline_rf_attack.py\n",
    "# Baseline: Single-task Random Forest for attack_id prediction\n",
    "# Dataset: CIC IoT-IDAD 2024 (packet-based processed subset)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# ==============================================================\n",
    "# 1. Imports & Paths, Configurations, Constants\n",
    "# ==============================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parents[0]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "TRAIN_PATH = PROCESSED_DIR / \"packets_train.csv\"\n",
    "VAL_PATH   = PROCESSED_DIR / \"packets_val.csv\"\n",
    "TEST_PATH  = PROCESSED_DIR / \"packets_test.csv\"\n",
    "ATTACK_LABEL_MAP_PATH = PROCESSED_DIR / \"attack_label_mapping.json\"\n",
    "\n",
    "TARGET_COL = \"attack_id\"\n",
    "SUBSAMPLE_N = 300_000  # RF can handle more than KNN but still heavy\n",
    "\n",
    "RF_CONFIG = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "    \"class_weight\": \"balanced_subsample\",\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Using processed data from:\", PROCESSED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cec7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2126280, 139)\n",
      "Val   shape: (455632, 139)\n",
      "Test  shape: (455632, 139)\n",
      "Number of attack classes: 8\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 2. Load Processed Data\n",
    "# ==============================================================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df   = pd.read_csv(VAL_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val   shape:\", val_df.shape)\n",
    "print(\"Test  shape:\", test_df.shape)\n",
    "\n",
    "with open(ATTACK_LABEL_MAP_PATH, \"r\") as f:\n",
    "    attack_label_mapping = json.load(f)[\"id_to_attack\"]\n",
    "\n",
    "num_attacks = len(attack_label_mapping)\n",
    "print(\"Number of attack classes:\", num_attacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb13fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of feature columns: 119\n",
      "Example features: ['stream', 'src_port', 'dst_port', 'inter_arrival_time', 'time_since_previously_displayed_frame', 'port_class_dst', 'l4_tcp', 'l4_udp', 'ttl', 'eth_size', 'tcp_window_size', 'payload_entropy', 'handshake_cipher_suites_length', 'handshake_ciphersuites', 'handshake_extensions_length']\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 3. Feature Selection (Numeric Only)\n",
    "# ==============================================================\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in [TARGET_COL, \"device_id\"]]\n",
    "\n",
    "print(\"\\nNumber of feature columns:\", len(feature_cols))\n",
    "print(\"Example features:\", feature_cols[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ac7499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning NaN/Inf...\n",
      "  [train] NaN before fill: 20652772, filling with 0.\n",
      "  [val] NaN before fill: 4432636, filling with 0.\n",
      "  [test] NaN before fill: 4426542, filling with 0.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 4. Cleaning: NaN / Inf Handling\n",
    "# ==============================================================\n",
    "\n",
    "def clean_df(df: pd.DataFrame, feature_cols, name: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    nan_before = df[feature_cols].isna().sum().sum()\n",
    "    if nan_before > 0:\n",
    "        print(f\"  [{name}] NaN before fill: {nan_before}, filling with 0.\")\n",
    "        df[feature_cols] = df[feature_cols].fillna(0)\n",
    "    return df\n",
    "\n",
    "print(\"\\nCleaning NaN/Inf...\")\n",
    "train_df = clean_df(train_df, feature_cols, \"train\")\n",
    "val_df   = clean_df(val_df, feature_cols, \"val\")\n",
    "test_df  = clean_df(test_df, feature_cols, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c2f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardising features (z-score on train stats)...\n",
      "  [train] NaN after std: 0, Inf: 0\n",
      "  [val] NaN after std: 0, Inf: 0\n",
      "  [test] NaN after std: 0, Inf: 0\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 5. Standardisation (Z-score)\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\nStandardising features (z-score on train stats)...\")\n",
    "means = train_df[feature_cols].mean()\n",
    "stds  = train_df[feature_cols].std().replace(0, 1.0)\n",
    "\n",
    "def standardise(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[feature_cols] = (df[feature_cols] - means) / stds\n",
    "    df[feature_cols] = df[feature_cols].clip(-10, 10)\n",
    "    n_nan = df[feature_cols].isna().sum().sum()\n",
    "    n_inf = np.isinf(df[feature_cols].values).sum()\n",
    "    print(f\"  [{name}] NaN after std: {n_nan}, Inf: {n_inf}\")\n",
    "    if n_nan > 0 or n_inf > 0:\n",
    "        raise ValueError(f\"Found NaN/Inf in {name} after standardisation.\")\n",
    "    return df\n",
    "\n",
    "train_df = standardise(train_df, \"train\")\n",
    "val_df   = standardise(val_df, \"val\")\n",
    "test_df  = standardise(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949f0c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full training size: 2126280\n",
      "Subsampled training size for RF: 300000\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 6. Numpy Arrays + Optional Subsampling\n",
    "# ==============================================================\n",
    "\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[TARGET_COL].values\n",
    "\n",
    "X_val   = val_df[feature_cols].values\n",
    "y_val   = val_df[TARGET_COL].values\n",
    "\n",
    "X_test  = test_df[feature_cols].values\n",
    "y_test  = test_df[TARGET_COL].values\n",
    "\n",
    "print(\"\\nFull training size:\", X_train.shape[0])\n",
    "\n",
    "if SUBSAMPLE_N is not None and X_train.shape[0] > SUBSAMPLE_N:\n",
    "    idx = np.random.choice(X_train.shape[0], size=SUBSAMPLE_N, replace=False)\n",
    "    X_train_sub = X_train[idx]\n",
    "    y_train_sub = y_train[idx]\n",
    "    print(f\"Subsampled training size for RF: {X_train_sub.shape[0]}\")\n",
    "else:\n",
    "    X_train_sub = X_train\n",
    "    y_train_sub = y_train\n",
    "    print(\"Using full training set for RF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b55fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# 7. Evaluation Helper\n",
    "# ==============================================================\n",
    "\n",
    "def evaluate_classifier(name, clf, X_val, y_val, X_test, y_test):\n",
    "    attack_names = [attack_label_mapping[str(i)] for i in range(len(attack_label_mapping))]\n",
    "\n",
    "    for split_name, X, y in [(\"Val\", X_val, y_val), (\"Test\", X_test, y_test)]:\n",
    "        y_pred = clf.predict(X)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        macro_f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "\n",
    "        print(f\"\\n[{name}] {split_name} Accuracy: {acc:.4f}, Macro-F1: {macro_f1:.4f}\")\n",
    "        print(f\"[{name}] {split_name} classification report:\")\n",
    "        print(classification_report(\n",
    "            y,\n",
    "            y_pred,\n",
    "            target_names=attack_names,\n",
    "            digits=4,\n",
    "            zero_division=0,\n",
    "        ))\n",
    "        print(f\"[{name}] {split_name} confusion matrix:\")\n",
    "        print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ec4afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest baseline with config: {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'n_jobs': -1, 'class_weight': 'balanced_subsample', 'random_state': 42}\n",
      "Random Forest training complete.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 8. Train Random Forest Baseline\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\nTraining Random Forest baseline with config:\", RF_CONFIG)\n",
    "rf = RandomForestClassifier(**RF_CONFIG)\n",
    "rf.fit(X_train_sub, y_train_sub)\n",
    "print(\"Random Forest training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8703cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RandomForest] Val Accuracy: 0.9887, Macro-F1: 0.9867\n",
      "[RandomForest] Val classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.9784    0.9928    0.9856     67500\n",
      " brute force     0.9983    0.9824    0.9903     19721\n",
      "        ddos     0.9983    0.9926    0.9954     67500\n",
      "         dos     0.9952    0.9894    0.9923     67500\n",
      "       mirai     0.9998    0.9936    0.9967     67500\n",
      "       recon     0.9880    0.9835    0.9857     67500\n",
      "    spoofing     0.9952    0.9881    0.9916     67500\n",
      "   web-based     0.9365    0.9764    0.9560     30911\n",
      "\n",
      "    accuracy                         0.9887    455632\n",
      "   macro avg     0.9862    0.9873    0.9867    455632\n",
      "weighted avg     0.9889    0.9887    0.9888    455632\n",
      "\n",
      "[RandomForest] Val confusion matrix:\n",
      "[[67012     4     9    19     3    55    37   361]\n",
      " [  115 19374     9    20     0     9     6   188]\n",
      " [  164     3 66998   125     0   111     1    98]\n",
      " [  288     5    77 66783     2   209    13   123]\n",
      " [   42     1     4     9 67068    41   143   192]\n",
      " [  272     8    13    85     2 66385    55   680]\n",
      " [  194     1     2    22     3   178 66695   405]\n",
      " [  401    11     3    42     2   203    67 30182]]\n",
      "\n",
      "[RandomForest] Test Accuracy: 0.9885, Macro-F1: 0.9864\n",
      "[RandomForest] Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.9793    0.9929    0.9861     67500\n",
      " brute force     0.9984    0.9821    0.9902     19722\n",
      "        ddos     0.9980    0.9924    0.9952     67500\n",
      "         dos     0.9949    0.9887    0.9918     67500\n",
      "       mirai     0.9997    0.9937    0.9967     67500\n",
      "       recon     0.9874    0.9825    0.9850     67500\n",
      "    spoofing     0.9948    0.9882    0.9915     67500\n",
      "   web-based     0.9349    0.9762    0.9551     30910\n",
      "\n",
      "    accuracy                         0.9885    455632\n",
      "   macro avg     0.9859    0.9871    0.9864    455632\n",
      "weighted avg     0.9887    0.9885    0.9886    455632\n",
      "\n",
      "[RandomForest] Test confusion matrix:\n",
      "[[67024     5     6    24     1    49    29   362]\n",
      " [  129 19369     7     9     3    17     6   182]\n",
      " [  138     2 66990   133     0   137     4    96]\n",
      " [  294     3    92 66740     0   214    13   144]\n",
      " [   45     1     6    21 67077    37   136   177]\n",
      " [  269     4    14    99     3 66322    72   717]\n",
      " [  162     4     3    23     4   177 66704   423]\n",
      " [  379    13     4    32     6   216    86 30174]]\n",
      "\n",
      "Done (Random Forest baseline).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 9. Evaluate\n",
    "# ==============================================================\n",
    "\n",
    "evaluate_classifier(\"RandomForest\", rf, X_val, y_val, X_test, y_test)\n",
    "\n",
    "print(\"\\nDone (Random Forest baseline).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
