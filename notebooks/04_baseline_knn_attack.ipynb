{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/naeemulhassan/naeem-p/Cloud-Deployed-Multitask-IoT-IDS\n",
      "Using processed data from: /Users/naeemulhassan/naeem-p/Cloud-Deployed-Multitask-IoT-IDS/data/processed\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# --------------------------------------------------------------\n",
    "# 04_baseline_knn_attack.py\n",
    "# Baseline: Single-task KNN classifier for attack_id prediction\n",
    "# Dataset: CIC IoT-IDAD 2024 (packet-based processed subset)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# ==============================================================\n",
    "# 1. Imports,  Paths, Configurations, Constants\n",
    "# ==============================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve().parents[0]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "TRAIN_PATH = PROCESSED_DIR / \"packets_train.csv\"\n",
    "VAL_PATH   = PROCESSED_DIR / \"packets_val.csv\"\n",
    "TEST_PATH  = PROCESSED_DIR / \"packets_test.csv\"\n",
    "ATTACK_LABEL_MAP_PATH = PROCESSED_DIR / \"attack_label_mapping.json\"\n",
    "\n",
    "TARGET_COL = \"attack_id\"\n",
    "SUBSAMPLE_N = 200_000\n",
    "\n",
    "N_NEIGHBORS = 5\n",
    "N_JOBS = -1\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Using processed data from:\", PROCESSED_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09ca8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2126280, 139)\n",
      "Val   shape: (455632, 139)\n",
      "Test  shape: (455632, 139)\n",
      "Number of attack classes: 8\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 2. Load Processed Data\n",
    "# ==============================================================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df   = pd.read_csv(VAL_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val   shape:\", val_df.shape)\n",
    "print(\"Test  shape:\", test_df.shape)\n",
    "\n",
    "with open(ATTACK_LABEL_MAP_PATH, \"r\") as f:\n",
    "    attack_label_mapping = json.load(f)[\"id_to_attack\"]\n",
    "\n",
    "num_attacks = len(attack_label_mapping)\n",
    "print(\"Number of attack classes:\", num_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf36936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of feature columns: 119\n",
      "Example features: ['stream', 'src_port', 'dst_port', 'inter_arrival_time', 'time_since_previously_displayed_frame', 'port_class_dst', 'l4_tcp', 'l4_udp', 'ttl', 'eth_size', 'tcp_window_size', 'payload_entropy', 'handshake_cipher_suites_length', 'handshake_ciphersuites', 'handshake_extensions_length']\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 3. Select Features (Numeric Only)\n",
    "# ==============================================================\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "feature_cols = [c for c in numeric_cols if c not in [TARGET_COL, \"device_id\"]]\n",
    "\n",
    "print(\"\\nNumber of feature columns:\", len(feature_cols))\n",
    "print(\"Example features:\", feature_cols[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "919a24f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning NaN/Inf...\n",
      "  [train] NaN before fill: 20652772, filling with 0.\n",
      "  [val] NaN before fill: 4432636, filling with 0.\n",
      "  [test] NaN before fill: 4426542, filling with 0.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 4. Cleaning: Remove NaN / Inf Values\n",
    "# ==============================================================\n",
    "\n",
    "def clean_df(df: pd.DataFrame, feature_cols, name: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    nan_before = df[feature_cols].isna().sum().sum()\n",
    "    if nan_before > 0:\n",
    "        print(f\"  [{name}] NaN before fill: {nan_before}, filling with 0.\")\n",
    "        df[feature_cols] = df[feature_cols].fillna(0)\n",
    "    return df\n",
    "\n",
    "print(\"\\nCleaning NaN/Inf...\")\n",
    "train_df = clean_df(train_df, feature_cols, \"train\")\n",
    "val_df   = clean_df(val_df, feature_cols, \"val\")\n",
    "test_df  = clean_df(test_df, feature_cols, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e534a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardising features (z-score using train stats)...\n",
      "  [train] NaN after std: 0, Inf: 0\n",
      "  [val] NaN after std: 0, Inf: 0\n",
      "  [test] NaN after std: 0, Inf: 0\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 5. Standardisation (Z-score)\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\nStandardising features (z-score using train stats)...\")\n",
    "\n",
    "means = train_df[feature_cols].mean()\n",
    "stds  = train_df[feature_cols].std().replace(0, 1.0)\n",
    "\n",
    "def standardise(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[feature_cols] = (df[feature_cols] - means) / stds\n",
    "    df[feature_cols] = df[feature_cols].clip(-10, 10)\n",
    "    \n",
    "    n_nan = df[feature_cols].isna().sum().sum()\n",
    "    n_inf = np.isinf(df[feature_cols].values).sum()\n",
    "    print(f\"  [{name}] NaN after std: {n_nan}, Inf: {n_inf}\")\n",
    "    if n_nan > 0 or n_inf > 0:\n",
    "        raise ValueError(f\"Found NaN/Inf in {name} after standardisation.\")\n",
    "    return df\n",
    "\n",
    "train_df = standardise(train_df, \"train\")\n",
    "val_df   = standardise(val_df, \"val\")\n",
    "test_df  = standardise(test_df, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e8e046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full training size: 2126280\n",
      "Subsampled training size for KNN: 200000\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 6. Convert to Numpy + Optional Subsampling\n",
    "# ==============================================================\n",
    "\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[TARGET_COL].values\n",
    "\n",
    "X_val   = val_df[feature_cols].values\n",
    "y_val   = val_df[TARGET_COL].values\n",
    "\n",
    "X_test  = test_df[feature_cols].values\n",
    "y_test  = test_df[TARGET_COL].values\n",
    "\n",
    "print(\"\\nFull training size:\", X_train.shape[0])\n",
    "\n",
    "if SUBSAMPLE_N is not None and X_train.shape[0] > SUBSAMPLE_N:\n",
    "    idx = np.random.choice(X_train.shape[0], size=SUBSAMPLE_N, replace=False)\n",
    "    X_train_sub = X_train[idx]\n",
    "    y_train_sub = y_train[idx]\n",
    "    print(f\"Subsampled training size for KNN: {X_train_sub.shape[0]}\")\n",
    "else:\n",
    "    X_train_sub = X_train\n",
    "    y_train_sub = y_train\n",
    "    print(\"Using full training set for KNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f9f805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================\n",
    "# 7. Evaluation Helper\n",
    "# ==============================================================\n",
    "\n",
    "def evaluate_classifier(name, clf, X_val, y_val, X_test, y_test):\n",
    "    attack_names = [attack_label_mapping[str(i)] for i in range(len(attack_label_mapping))]\n",
    "\n",
    "    for split_name, X, y in [(\"Val\", X_val, y_val), (\"Test\", X_test, y_test)]:\n",
    "        y_pred = clf.predict(X)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "        macro_f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "\n",
    "        print(f\"\\n[{name}] {split_name} Accuracy: {acc:.4f}, Macro-F1: {macro_f1:.4f}\")\n",
    "        print(classification_report(\n",
    "            y, y_pred,\n",
    "            target_names=attack_names,\n",
    "            digits=4,\n",
    "            zero_division=0,\n",
    "        ))\n",
    "        print(f\"[{name}] {split_name} confusion matrix:\")\n",
    "        print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30ffaeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training KNN baseline...\n",
      "KNN training complete.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 8. Train KNN Baseline\n",
    "# ==============================================================\n",
    "\n",
    "print(\"\\nTraining KNN baseline...\")\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=N_NEIGHBORS,\n",
    "    n_jobs=N_JOBS,\n",
    ")\n",
    "\n",
    "knn.fit(X_train_sub, y_train_sub)\n",
    "print(\"KNN training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b76f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KNN] Val Accuracy: 0.9322, Macro-F1: 0.9265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.8480    0.9443    0.8936     67500\n",
      " brute force     0.9848    0.9539    0.9691     19721\n",
      "        ddos     0.9935    0.9833    0.9884     67500\n",
      "         dos     0.9806    0.9562    0.9683     67500\n",
      "       mirai     0.9934    0.9843    0.9888     67500\n",
      "       recon     0.9156    0.9081    0.9119     67500\n",
      "    spoofing     0.9082    0.8809    0.8943     67500\n",
      "   web-based     0.8176    0.7788    0.7977     30911\n",
      "\n",
      "    accuracy                         0.9322    455632\n",
      "   macro avg     0.9302    0.9237    0.9265    455632\n",
      "weighted avg     0.9335    0.9322    0.9324    455632\n",
      "\n",
      "[KNN] Val confusion matrix:\n",
      "[[63737    16    44   309    42  1017  1446   889]\n",
      " [  398 18812    13    48     8   102   156   184]\n",
      " [  576    25 66373    95    10   161   127   133]\n",
      " [ 1553    35   116 64544    37   506   350   359]\n",
      " [  341     7    32    78 66440   162   198   242]\n",
      " [ 2229    38    92   278   109 61299  1910  1545]\n",
      " [ 3427    82    66   232   130  2085 59460  2018]\n",
      " [ 2899    88    69   234   107  1616  1824 24074]]\n",
      "\n",
      "[KNN] Test Accuracy: 0.9320, Macro-F1: 0.9264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign     0.8501    0.9432    0.8942     67500\n",
      " brute force     0.9844    0.9546    0.9693     19722\n",
      "        ddos     0.9922    0.9836    0.9879     67500\n",
      "         dos     0.9810    0.9550    0.9678     67500\n",
      "       mirai     0.9936    0.9843    0.9889     67500\n",
      "       recon     0.9141    0.9070    0.9106     67500\n",
      "    spoofing     0.9067    0.8827    0.8945     67500\n",
      "   web-based     0.8176    0.7785    0.7976     30910\n",
      "\n",
      "    accuracy                         0.9320    455632\n",
      "   macro avg     0.9300    0.9236    0.9264    455632\n",
      "weighted avg     0.9333    0.9320    0.9322    455632\n",
      "\n",
      "[KNN] Test confusion matrix:\n",
      "[[63669    21    52   302    52  1037  1490   877]\n",
      " [  435 18826     5    54    11   107   137   147]\n",
      " [  488    29 66392    87     9   218   124   153]\n",
      " [ 1593    32   142 64461    32   486   397   357]\n",
      " [  322    19    41    86 66440   192   183   217]\n",
      " [ 2195    40   122   295   108 61225  1923  1592]\n",
      " [ 3345    73    84   185   118  2089 59581  2025]\n",
      " [ 2851    84    74   242    97  1623  1875 24064]]\n",
      "\n",
      "Done (KNN baseline).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# 9. Evaluate\n",
    "# ==============================================================\n",
    "\n",
    "evaluate_classifier(\"KNN\", knn, X_val, y_val, X_test, y_test)\n",
    "\n",
    "print(\"\\nDone (KNN baseline).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
