# ğŸ“¡ Cloudâ€‘Deployed Multitask IoT Intrusion & Device Detection Platform
**MSc Artificial Intelligence â€“ Applied Research Project (Dublin Business School)**

This repository contains the **complete, implemented artefact** for the MSc Applied Research Project.
All sections below describe the code, notebooks, experiments, and results implemented and executed as part of this project.

---

## ğŸ‘¤ Author & Supervisor

**Author:** Naeem ul Hassan  
Strategic Engineering Manager | MSc Artificial Intelligence  
Dublin Business School, Ireland  
Email: naeemhassan09@gmail.com  
Phone: +353 87 031 1061 | +92 336 6622999  

**Supervisor:** Dr. Syed Mustufa  
Lecturer & Research Supervisor  
Dublin Business School  
Email: syed.mustufa@dbs.ie  

---

## ğŸ¯ Project Overview (Implemented Scope)

This project delivers an **endâ€‘toâ€‘end IoT security analytics system** that performs:

1. **Network Intrusion Detection (primary task)**
2. **IoT Device Identification (secondary task)**

using the **packetâ€‘based labeled subset of the CIC IoTâ€‘IDAD 2024 dataset**.

The system includes:
- Classical **singleâ€‘task baselines** (KNN, Random Forest, XGBoost)
- A **best singleâ€‘task deep learning model** (CNNâ€‘based)
- A **final multitask CNN model** with staged training
- A **FastAPI backend**
- A **frontend UI for demo & examiner review**
- **AWS CI/CD** using CodePipeline + CodeBuild
- **Docker + Amazon ECR + ECS (Fargateâ€‘ready)** deployment

---

## ğŸ““ Notebooks (What Is Implemented)

The `notebooks/` directory **does implement and execute** the following baselines:

### âœ… Implemented singleâ€‘task baselines
- **Kâ€‘Nearest Neighbours (KNN)**
- **Random Forest (RF)**
- **Classical XGBoost**

These are trained and evaluated for **intrusion detection (attack_id)** only and are used as **comparative baselines**.

### Notebook responsibilities
- Data inspection & validation
- Baseline model training
- Confusion matrices & classification reports
- Validation vs test comparison

---

## ğŸ“Š Baseline Results (From Executed Runs)

### KNN (Singleâ€‘Task Intrusion Detection)
- **Test Accuracy:** 0.9320  
- **Macroâ€‘F1:** 0.9264  

### Random Forest (Singleâ€‘Task Intrusion Detection)
- **Test Accuracy:** 0.9885  
- **Macroâ€‘F1:** 0.9864  

### XGBoost (Singleâ€‘Task Intrusion Detection)
- **Test Accuracy:** 0.9952  
- **Macroâ€‘F1:** 0.9942  



These results are generated directly from the notebook and training scripts and are reported in the dissertation for benchmarking.

---

## ğŸ§  Final Model â€“ Multitask CNN (Implemented)

### Architecture
- **Shared CNN backbone** for packetâ€‘feature extraction
- **Two taskâ€‘specific heads**
  - Intrusion / attack classification
  - IoT device identification
- **Staged training strategy**
  1. Train attack head
  2. Freeze backbone + attack head, train device head
  3. Joint fineâ€‘tuning (attackâ€‘dominant loss weighting)

---

## ğŸ“ˆ Final Multitask Results (Stageâ€‘3)

### Intrusion Detection (Attack Head â€“ Test)
- **Accuracy:** **0.9480**
- **Macroâ€‘F1:** 0.9412

### Device Identification (Device Head â€“ Test)
- **Overall Accuracy:** **0.6517**
- Largeâ€‘scale multiâ€‘class problem (90+ devices)
- Results reported using topâ€‘device breakdowns (as in dissertation)

These results represent the **final evaluated artefact** of the project.

---

### Key endpoints (Implemented)

- `GET /health` â€“ Service health check and basic artefact status (model loaded, feature count)
- `POST /predict` â€“ Single-record inference via JSON payload (attack + device), includes latency and top-k probabilities
- `POST /api/predict-file` â€“ Batch inference via CSV upload (raw CIC packet CSV); returns distributions, timing breakdown, throughput and capped per-row predictions
- `GET /api/schema` â€“ Returns model feature schema (feature names + expected count)
- `GET /api/labels` â€“ Returns label map summary (counts + sample mappings)
- `GET /api/info` â€“ Model metadata and (if available) stored evaluation summary
- `GET /docs` â€“ Swagger UI (auto-generated by FastAPI)
- `GET /openapi.json` â€“ OpenAPI schema (auto-generated by FastAPI)
- `GET /redoc` â€“ ReDoc UI (auto-generated by FastAPI)

---

## ğŸ–¥ Frontend UI (Implemented)

A frontend UI is included to:
- Provide a **visual demo for examiners**
- Submit feature vectors / JSON payloads
- Display predicted:
  - Intrusion class
  - Device identity

The frontend **does not perform ML inference**.
All predictions are served via the FastAPI backend.

---

## ğŸ§± Endâ€‘toâ€‘End Architecture

```
Packetâ€‘based CIC IoTâ€‘IDAD 2024
            â”‚
            â–¼
   Preprocessing & splits
            â”‚
            â–¼
   Baselines (KNN / RF / XGB )
  
            â”‚
            â–¼
   Multitask CNN (staged training)
            â”‚
            â–¼
   FastAPI backend
            â”‚
            â–¼
        Frontend UI
            â”‚
            â–¼
 Docker â†’ ECR â†’ ECS
            â”‚
            â–¼
 AWS CodePipeline
```

---

## ğŸ“ Repository Structure (Actual)

```
Cloud-Deployed-Multitask-IoT-IDS/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI backend
â”‚   â”œâ”€â”€ data/           # Data loading code
â”œâ”€â”€ frontend/             # Frontend UI
â”‚   â””â”€â”€ src/
|   |   â””â”€â”€ components/
â”œâ”€â”€ notebooks/            # Baselines + EDA + Model Training
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ Dockerfile.fullstack
â”‚   â””â”€â”€ ecs/              # ECS configs
â”œâ”€â”€ reports/              # Results, tables, figures
â”œâ”€â”€ data/
â”œâ”€â”€ buildspec.yml     # AWS CodeBuild
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Local Setup

```bash
git clone https://github.com/naeemhassan09/Cloud-Deployed-Multitask-IoT-IDS.git
cd Cloud-Deployed-Multitask-IoT-IDS
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ–¥ Frontend â€“ Local Execution

The frontend UI is a lightweight client used for demonstration and examiner review.
It does not perform inference locally and communicates with the FastAPI backend via HTTP.

### Prerequisites
- Node.js â‰¥ 18
- Backend FastAPI service running locally or on ECS

### Install dependencies
```bash
cd frontend
npm install
npm run dev
```
---
## ğŸ§ª Training

### Baselines
Executed via notebook in notebooks/07_multitask_cnn_staged.py.

---

## ğŸ³ Docker & AWS CI/CD (Implemented)

- **CI/CD:** AWS CodePipeline
- **Build:** AWS CodeBuild
- **Image Registry:** Amazon ECR
- **Runtime:** AWS ECS (Fargateâ€‘ready)

Pipeline:
```
GitHub â†’ aws CodePipeline â†’ aws CodeBuild â†’ aws ECR â†’ aws ECS
```

---
## â˜ï¸ Cloud Deployment â€“ ECS Runtime Performance (Live Server Results)

The final **multitask CNN model** was deployed on **AWS ECS (Fargate)** using the current task definition.  
The following metrics were captured from a **live inference run** on the deployed service.

### ğŸ”¢ Evaluation Setup
- **Deployment:** AWS ECS (Fargate)
- **Model:** Multitask CNN (shared backbone + dual heads)
- **Input size:** 5,000 packet-level records
- **Tasks:**
  - Intrusion detection (attack vs benign)
  - IoT device identification
- **Inference mode:** Batch REST request via FastAPI

---

### ğŸ“Š Traffic Composition
| Class   | Percentage |
|--------|------------|
| Benign | **43.2%**  |
| Attacks| **56.8%**  |

This represents a realistic, attack-heavy traffic mix suitable for stress-testing cloud inference.

---

### â±ï¸ Latency Breakdown
| Stage            | Time |
|------------------|------|
| **Total latency**| **3,885.3 ms** |
| Preprocessing   | 80.7 ms (**0.016 ms/row**) |
| Inference       | 3,653.0 ms (**0.731 ms/row**) |

- Preprocessing overhead is minimal.
- Inference dominates latency, as expected for deep learning workloads.

---

### ğŸš€ Throughput
- **Throughput:** **1,369 rows/second**

The service sustains ~1.3K packets/s while performing **dual-task inference** in a single forward pass.

---

### ğŸ§  Model Snapshot (Deployed)
- **Architecture:** Multitask CNN
- **Backbone:** Shared CNN feature extractor
- **Heads:**
  - Intrusion classification head
  - Device identification head
- **Inference:** Single forward pass for both tasks

---

### ğŸ§ª Interpretation 
- Demonstrates **stable real-time performance** on managed cloud infrastructure.
- Multitask inference avoids duplicated pipelines while delivering operational throughput.
- Confirms **practical deployability** of the proposed architecture on AWS ECS.



---
# ğŸ“š About the Author

I work across AI, Deep Learning, IoT Security, and Cloud DevOps.  
My expertise spans full ML lifecycle â€” ETL â†’ model â†’ API â†’ AWS deployment.
From data preparation and model development to API integration and cloud deployment.
## Core Capabilities

### Machine Learning & AI
- Convolutional Neural Networks (CNNs) for packet-level traffic analysis
- Multitask learning for joint intrusion detection and device identification
- Classical machine-learning baselines (KNN, Random Forest, XGBoost)
- IoT device fingerprinting using network traffic features
- Network intrusion detection and multi-class attack classification
- Model evaluation using accuracy, Macro-F1, confusion matrices, and class-wise analysis

### Cloud & DevOps
- AWS ECS, ECR, Lambda, CloudFront, WAF, RDS  
- Docker & container orchestration  
- GitHub and AWS Codepipeline CI/CD  
- Monitoring & observability are provided via:
- AWS CloudWatch logs
- ECS CPU and memory metrics


### Software Engineering
- Python, FastAPI, Node.js, NestJS  
- Scalable microservices  
- Logging, observability, cloud automation  
---
## ğŸ“œ License

MIT License (recommended for academic research use).

---


All results and claims are **fully reproducible from code and notebooks**.
---